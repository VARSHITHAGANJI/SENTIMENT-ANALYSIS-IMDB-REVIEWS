{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJECT_AI20BTECH11009.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF4wqII9m-vf"
      },
      "source": [
        "PROJECT : SENTIMENT ANALYSIS (IMDB REVIEWS) \n",
        "\n",
        "AUTHOR  : GANJI VARSHITHA\n",
        "\n",
        "ROLL NO : AI20BTECH11009\n",
        "\n",
        "ML MODEL: RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDzRKI8cMMvj",
        "outputId": "06cb3382-c4fa-4e4b-b630-9068b8e1215a"
      },
      "source": [
        "#Importing all the required libraries\n",
        "import numpy as np\n",
        "import pandas as pd #For loading and handling dataset\n",
        "import re\n",
        "from string import punctuation\n",
        "import nltk #for nlp\n",
        "from nltk.corpus import stopwords # for the collection of stopping words\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split #for splitting the data into training and testing\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer #To encode the text into integer array\n",
        "from keras.preprocessing.sequence import pad_sequences #Helps in padding and truncating the sequence\n",
        "import matplotlib.pyplot as plt #For plotting graphs\n",
        "from keras.models import Sequential, load_model #We are using sequential model and we'll also load(call) the saved model\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout #Layers in RNN architecture\n",
        "from keras.callbacks import ModelCheckpoint #Helps to save the model\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzBaRUnYm43B"
      },
      "source": [
        "Loading the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "soKKtqvPnY28",
        "outputId": "c3bc55cb-82e4-4a70-ac3a-8ab017f13bf4"
      },
      "source": [
        "dataset = pd.read_csv('movie_data.csv')\n",
        "print(dataset.tail())#Previews the data with first five rows \n",
        "dataset.describe() #Shows the statistical analysis"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  review  sentiment\n",
            "49995  The 1998 version of \"Psycho\" needed to be set ...          0\n",
            "49996  IT IS So Sad. Even though this was shot with f...          0\n",
            "49997  Over several years of looking for half-decent ...          0\n",
            "49998  ***Possible Plot Spoilers***<br /><br />I ador...          0\n",
            "49999  While I can't say whether or not Larry Hama ev...          1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          sentiment\n",
              "count  50000.000000\n",
              "mean       0.500000\n",
              "std        0.500005\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.500000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKheBfOwpPSO",
        "outputId": "9fec816e-147e-4a98-de21-9ec48d4a3cad"
      },
      "source": [
        "#Exploring the data\n",
        "#Finding number of unique outputs\n",
        "Classes = np.unique(dataset['sentiment'])\n",
        "#Finding the maximum number of unique words\n",
        "Max_num_words = len(np.unique(dataset['review']))\n",
        "\n",
        "#printing observations\n",
        "print('Classes: ',Classes)\n",
        "print('Maximum number of unique words: ',Max_num_words)\n",
        "\n",
        "\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classes:  [0 1]\n",
            "Maximum number of unique words:  49582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vzGzvULpTiE"
      },
      "source": [
        "\n",
        "stop_words = stopwords.words('english')#creating a list of stop words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def training_samples():\n",
        "  dataset=pd.read_csv('movie_data.csv')\n",
        "  input_data=dataset['review']\n",
        "  output_data=dataset['sentiment']\n",
        "  #pre-processing data\n",
        "  input_data=input_data.apply(lambda x: x.lower())#making the words lowercase\n",
        "  input_data = input_data.apply(lambda x:''.join([c for c in x if c not in punctuation]))#removing characters\n",
        "  input_data=input_data.apply(lambda x : [i for i in x.split() if i not in stop_words]) #removing stopwords\n",
        "  \n",
        "  return input_data, output_data\n",
        "\n",
        "\n",
        "\n",
        "input_data, output_data = training_samples()\n",
        "\n",
        "\n",
        "#Finding the average of words in review\n",
        "length = [len(i) for i in input_data]\n",
        "max_length=np.mean(length)\n",
        "\n",
        "\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTwFgqlKnsy"
      },
      "source": [
        "TOKENIZE:\n",
        "\n",
        "Neural network takes numerical input hence we need to encode the review data into integers.\n",
        "\n",
        "\n",
        "*   Each unique word is indexed using fit_on_texts method\n",
        "*   Training and testing inputs are converted to integers using texts_to_sequences method\n",
        "\n",
        "Also, each review is having different length hence we need to pad the sequences by adding 0 and truncate the words to same length (i.e average length of review)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ozri2tMPkM"
      },
      "source": [
        "tokens= Tokenizer(lower=False)# Since the data is converted to lowercase before\n",
        "tokens.fit_on_texts(input_data)\n",
        "input_data = tokens.texts_to_sequences(input_data)\n",
        "\n",
        "input_data = pad_sequences(input_data,maxlen=127,padding='post',truncating='post')\n",
        "\n",
        "train_input,test_input,train_output,test_output=train_test_split(input_data,output_data,test_size=0.2)#test_input_size=0.2*input_data\n",
        "\n",
        "total_words=len(tokens.word_index) + 1 #word_index0 is reserved to distinguish between pad and unknown\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3CXeWrqS4wa"
      },
      "source": [
        "Building RNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtC91gfqN4s7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48608ed-b37a-40f8-942e-47fed2e4b1ba"
      },
      "source": [
        "embed=32 # dimensions of embeddding\n",
        "LSTM_SIZE=64 #number of hidden layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words,embed,input_length=127))\n",
        "model.add(LSTM(LSTM_SIZE))\n",
        "model.add(Dense(1,activation='sigmoid'))#activation is sigmoid as output is either 0 or 1\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics =['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 127, 32)           5809408   \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,834,305\n",
            "Trainable params: 5,834,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byBs8c2VWZMg"
      },
      "source": [
        "Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmiQXh9UYeyW",
        "outputId": "a843ac36-a8af-4601-9929-add64454d82a"
      },
      "source": [
        "#Using mini-batch learning method with batch_size 200 and 5 epochs\n",
        "#Adding a callback called checkpoint which saves the model if accuracy is increased from previous epoch\n",
        "checkpoint=ModelCheckpoint('sentiment/LSTM.h5',monitor='accuracy',save_best_only=True,verbose=2)\n",
        "model.fit(train_input,train_output,batch_size=200,epochs=5,callbacks=[checkpoint])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 58s 280ms/step - loss: 0.6084 - accuracy: 0.6086\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.73652, saving model to sentiment/LSTM.h5\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 56s 280ms/step - loss: 0.1993 - accuracy: 0.9340\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.73652 to 0.93155, saving model to sentiment/LSTM.h5\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 56s 280ms/step - loss: 0.0991 - accuracy: 0.9710\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.93155 to 0.96978, saving model to sentiment/LSTM.h5\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 56s 279ms/step - loss: 0.0508 - accuracy: 0.9875\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.96978 to 0.98677, saving model to sentiment/LSTM.h5\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0368 - accuracy: 0.9921\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.98677 to 0.99182, saving model to sentiment/LSTM.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e3c1b89d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Q8Uk4MkpLf"
      },
      "source": [
        "TESTING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUjHT70vhY9H",
        "outputId": "e8794e4d-a9ef-4378-e595-22c9c6e14b38"
      },
      "source": [
        "pred = model.predict(test_input)#predicting the labels\n",
        "true=0\n",
        "correct=0\n",
        "ptrue=0\n",
        "for i,y in enumerate(test_output):\n",
        "  if pred[i]>0.5:#classifying predicted label as positive if the confidence value is greater than 0.5 and negative otherwise\n",
        "    ptrue+=1\n",
        "  if y==1:\n",
        "    true+=1\n",
        "  if ((pred[i]>0.5 and  y==1) or (pred[i]<0.5 and y==0)):\n",
        "    correct+=1\n",
        "\n",
        "print('Number of positive sentiment predictions:',ptrue)\n",
        "print('Real positive sentiment : ',true)\n",
        "print('Number of negative sentiment predictions:',len(test_input)-ptrue)\n",
        "print('Real negative sentiment : ',len(test_input)-true)\n",
        "print('Accuracy of the model is :',(correct/len(test_input))*100)\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive sentiment predictions: 5272\n",
            "Real positive sentiment :  5025\n",
            "Number of negative sentiment predictions: 4728\n",
            "Real negative sentiment :  4975\n",
            "Accuracy of the model is : 85.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4tm3ta3mB2A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}